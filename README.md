# Machine Learning Methods

## K-Nearest Algoritm
ğŸ”¸ A dataset which has categorical data (men-woman) has defined.
```
data = [["man",180,80], ["woman",160,60], ["man",170,70], ["man",175,74], ["man",175,70], ["man",160,69], ["woman",170,68], ["man",170,55], ["woman",155,55], ["woman",150,54], ["woman",152,60], ["woman",165,60]]
```

ğŸ”¸ Requested input from user for weight and height and they have been assigned to new variable.
```
height = input("Enter height: \n")
height = float(height) 
weight = input("Enter weight: \n")
weight = float(weight) 
new = [height,weight]
```
ğŸ”¸ A function has been created appropriate to dataset for calculate the eucledian distance. In here, input from user and dataset has been used as a parameter of function. In function,  differences beetween requested input from user and dataset rows has been calculated and taken its square root. As a result of this calculations, euclidian distance has been found.

```
def euclidean_distance(data,new):
 distance = ((data[1] - new[0]) ** 2) + ((data[2] - new[1]) ** 2)
    return math.sqrt(distance)
```
ğŸ”¸ A new list has been created. Created list has been defined as data = [â€œkategoriâ€, â€œboyâ€, â€œkiloâ€, â€œgirilen deÄŸer ile Ã¶klit uzaklÄ±ÄŸÄ±â€]. And then, this list has been sorted by distances.

```
for i in range(len(new)):
    data[i].append(euclidean_distance(data[i],new)) 
data.sort(key = lambda data: data[3])
```

ğŸ”¸ An input refers k value requested from user.

```
k = input("Please enter k value:\n")
k = int(k)
```

ğŸ”¸ Here, calculations has been done with two diferent approaches:

* **Plurality Vote Approach:** Smallest values has been choose according to k value. Which categories of chosen one was more than others, this category determined as predicted category.

```
woman = 0
man = 0

for i in range(0,k):
    if data[i][0] == "man":
        man += 1
    elif data[i][0] == "woman":
        woman += 1 
if woman > man:
    print("Plurality vote: Gender = woman")
else:
    print("Plurality vote: Gender = man")
```    
* **Weighted Vote Approach:** Here, the smallest distances to k value has been calculated. As a result of calculation; the category that gives biggest value is assinged as category of prediction.
```
for i in range(0,k):
    if (data[i][3] != 0):
        weights.append([i,(1/(data[i][3])**2)]) 
weights.sort(key = lambda data: data[1],reverse=True)
print("Weighted vote: Gender = ", data[weights[0][0]][0])
```
## Principal Component Analysis (PCA)

ğŸ”¸ dataX and dataY determinde manually.
```
dataX = 	[2.5,0.5,2.2,1.9,3.1,2.3,2,1,1.5,1.1]

dataY = 	[2.4,0.7,2.9,2.2,3,2.7,1.6,1.1,1.6,0.9]
```
 ğŸ”¸ Average values of each column has been calculated. With this, â€œcovariance matrixâ€ will created.
```
for i in range(len(dataX)):
    meanX += dataX[i] 
meanX =  meanX /len(dataX)

for i in range(len(dataY)):
    meanY += dataY[i] 
meanY =  meanY /len(dataY)
```
ğŸ”¸ The mean of each X and Y value was subtracted.
```
for i in range(len(dataX)):
    dataX[i] = dataX[i] - meanX
for i in range(len(dataY)):
    dataY[i] = dataY[i] - meanY
```
ğŸ”¸ X,X; X,Y; Y,X; Y,Y values has been calculated for â€œcovariance matrixâ€ components and each value has been assigned its related component.


* X,X
```
sum = 0.0
for i in range(len(dataX)):
    sum = sum +(dataX[i] * dataX[i])
sum = sum / (len(dataX)-1)
cov_matrix.append(sum)
```
* X,Y
```
sum = 0.0
for i in range(len(dataX)):
    sum = sum +(dataX[i] * dataY[i])
sum = sum / (len(dataX)-1)
cov_matrix.append(sum)
```
* Y,X
```
sum = 0.0
for i in range(len(dataX)):
    sum = sum +(dataX[i] * dataY[i])
sum = sum / (len(dataX)-1)
cov_matrix.append(sum)
```
* Y,Y
```
sum = 0.0
for i in range(len(dataY)):
    sum = sum +(dataY[i] * dataY[i])
sum = sum / (len(dataX)-1)
cov_matrix.append(sum)
```
ğŸ”¸ Printing â€œcovariance matrixâ€ to the screen.
```
print("Covariance Matrix: ",cov_matrix)
```
## K-means Clustering   
ğŸ”¸ The dataset has 200 exampke and in start position, 4 "center" has been determined.
```
dataset, classes = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=0.5, random_state=0)
```
ğŸ”¸ Columns of dataset, has 200 random examples, has been determined as "var1" and "var2".
```
df = pd.DataFrame(dataset, columns=['var1', 'var2'])
sns.scatterplot(data=df, x="var1", y="var2")
plt.show()
```

ğŸ”¸ K-means model has been determined. 
```
model = KMeans()
```
ğŸ”¸ Dataframe that has been created with 4 clusters assign to the model with different parameters.
```
kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df)
Counter(kmeans.labels_)
Counter({2: 50, 0: 50, 3: 50, 1: 50})
```
ğŸ”¸ Results of training step, each cluster has been visualized with different colors. (With seaborn library)
```
sns.scatterplot(data=df, x="var1", y="var2", hue=kmeans.labels_)
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], 
            marker="X", c="r", s=80, label="centroids")
plt.legend()
plt.show()
```
## Gaussian Naive Bayes Method

ğŸ”¸ The first index of data has been determined as weather and the second one has been playing state of football. 
```
data = 	[["R","N"], ["R","N"], ["C","Y"], ["S","Y"], ["S","Y"], ["S","N"], ["C","Y"], ["R","N"], ["R","Y"], ["S","Y"], ["R","Y"], ["C","Y"], ["C","Y"], ["S","N"]]
```
* In here: 
    
    R = Rainy

    C = Cloudy

    S = Sunny

    Y = Yes

    N = No

ğŸ”¸ Counter for whole yes number;
```
yes = 0
for i in range(len(data)):
    if data[i][1] == "Y" :
        yes += 1
```

ğŸ”¸ Counter for whole no number;
```
no = 0
for i in range(len(data)):
    if data[i][1] == "N" :
        no += 1
```
ğŸ”¸ Counter for whole "sunny" number;
```
sunny= 0
for i in range(len(data)):
    if data[i][0] == "S" :
        sunny += 1
```


Calculated counter of rainy days and assign to a counter called rainy.
```
yagmurlu = 0
for i in range(len(data)):
    if data[i][0] == "Y" :
        yagmurlu += 1
```
BÃ¼tÃ¼m â€œbulutluâ€larÄ±n sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œbulutluâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
bulutlu = 0
for i in range(len(data)):
    if data[i][0] == "B" :
        bulutlu += 1

BÃ¼tÃ¼m â€œgunesli evetâ€lerin sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œgunesliEâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
gunesliE = 0
for i in range(len(data)):
    if data[i][0] == "G" and data[i][1] == "E" :
        gunesliE += 1

BÃ¼tÃ¼m â€œgunesli hayÄ±râ€lerin sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œgunesliEâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
gunesliH = 0
for i in range(len(data)):
    if data[i][0] == "G" and data[i][1] == "H" :
        gunesliH += 1 

BÃ¼tÃ¼m â€œbulutlu evetâ€lerin sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œbulutluEâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
bulutluE = 0
for i in range(len(data)):
    if data[i][0] == "B" and data[i][1] == "E" :
        bulutluE += 1

BÃ¼tÃ¼m â€œbulutlu hayÄ±râ€larÄ±n sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œbulutluHâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
bulutluH = 0
for i in range(len(data)):
    if data[i][0] == "B" and data[i][1] == "H" :
        bulutluH += 1

BÃ¼tÃ¼m â€œyagmurlu evetâ€lerin sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œyagmurluEâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
yagmurluE = 0
for i in range(len(data)):
    if data[i][0] == "Y" and data[i][1] == "E" :
        yagmurluE += 1
        
BÃ¼tÃ¼m â€œyaÄŸmurlu hayÄ±râ€larÄ±n sayÄ±mÄ± yapÄ±lmaktadÄ±r ve â€œyagmurluHâ€ adÄ±ndaki bir sayÄ±cÄ±ya atÄ±lmaktadÄ±r.
yagmurluH = 0
for i in range(len(data)):
    if data[i][0] == "Y" and data[i][1] == "H" :
        yagmurluH += 1

KullanÄ±cÄ±dan hava durumu ve merak ettiÄŸi oynanma durumu iÃ§in bir girdi alÄ±ndÄ±.
havadurumu = input("Hava durumunu giriniz:\n GÃ¼neÅŸli iÃ§in G\n YaÄŸmurlu iÃ§in Y \n Bulutlu iÃ§in B\n")
oynama = input("Futbol oynanacak mÄ±?:\n Evet iÃ§in E\n HayÄ±r iÃ§in H \n")

KullanÄ±cÄ±dan alÄ±nan deÄŸerlere gÃ¶re her bir durum baÄŸÄ±ntÄ±sÄ±nÄ±n ortalamalarÄ± hesaplandÄ± ve hesaplanan deÄŸerler kullanÄ±cÄ±ya dÃ¶ndÃ¼rÃ¼ldÃ¼.
if havadurumu == "G" and oynama == "E":
    print(((gunesliE/evet)*(evet/len(data))) / (gunesli/len(data))) 
if havadurumu == "G" and oynama == "H":
    print( (gunesliH/hayir)*(hayir/len(data)) / (gunesli/len(data)) ) 
if havadurumu == "Y" and oynama == "E":
    print(((yagmurluE/evet)*(evet/len(data))) / (yagmurlu/len(data))) 
if havadurumu == "Y" and oynama == "H":
    print(((yagmurluH/hayir)*(hayir/len(data))) / (yagmurlu/len(data))) 
if havadurumu == "B" and oynama == "E":
    print(((bulutluE/evet)*(evet/len(data))) / (bulutlu/len(data))) 
if havadurumu == "B" and oynama == "H":
    print(((bulutluH/hayir)*(hayir/len(data))) / (bulutlu/len(data)))

## MULTINOMIAL NAIVE BAYES YÃ–NTEMÄ°
Kategorilerine uygun kelimelerin bulunduÄŸu veriseti tanÄ±mlandÄ±.
dataset = [["Chinese Beijing Chinese", "Ã‡"],
           ["Chinese Chinese Shangai", "Ã‡"],
           ["Chinese Macao Shangai", "Ã‡"],
            ["Tokyo Japan Chinese", "J"]]         

TanÄ±mlanan veriseti â€œdataframeâ€ olarak tanÄ±mlandÄ± ve kelimelin bulunduÄŸu sÃ¼tun â€œTextâ€ olarak, kategorilerin olduÄŸu sÃ¼tun â€œCategoriesâ€ olarak tanÄ±mlandÄ±.
dataset = pd.DataFrame(dataset)
dataset.columns = ["Text", "Categories"]

Verisetinde bulunan anlamsÄ±z kelimelerin Ã§Ä±karÄ±labilmesi iÃ§in â€œstopwordsâ€ kullanÄ±lmaktadÄ±r. 
nltk.download('stopwords')

Her bir kelimeler boÅŸluklarÄ± silinerek ve bÃ¼yÃ¼k harfleri kÃ¼Ã§Ã¼k harflere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek birleÅŸtirildi. BirleÅŸtirilen kelimeler corpus adÄ±ndaki yapÄ±ya atandÄ± ve bu sayede tanÄ±mlana yapÄ±labilecek.
corpus = []
for i in range(0, 3):
    text = re.sub('[^a-zA-Z]', '', dataset['Text'][i])
    text = text.lower()
    text = text.split()
    ps = PorterStemmer()
    text = ''.join(text)
    corpus.append(text)

Scikit-learn tarafÄ±ndan sunulan â€œCountVectorizerâ€ ile bir dokÃ¼man kolestiyonu bir terim vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
cv = CountVectorizer(max_features = 1500)

Verisetinde tanÄ±mlanan metinler  X olarak ve kategoriler y yani hedef olarak tanÄ±mlanmaktadÄ±r.
X = dataset.iloc[:, 0].values
y = dataset.iloc[:, 1].values
train = X

EÄŸitim yapÄ±labilmesi iÃ§in model yapÄ±landÄ±rmasÄ± yapÄ±lÄ±r ve tanÄ±mlanan X ve y deÄŸerleri modele fit edilir.
model = make_pipeline(TfidfVectorizer(), MultinomialNB())
model.fit(X, y)

Tahmin yapÄ±labilmesi iÃ§in bir fonksiyon tanÄ±mlanÄ±r. Bu sayede kullanÄ±cÄ±dan alÄ±nan bilgiyi fonksyiona parametre olarak gÃ¶nderdiÄŸimizde bize bilginin hangi kategoriye ait olduÄŸu deÄŸeri dÃ¶ndÃ¼rÃ¼lÃ¼r.
def predict_category(s, train=train, model=model):
    return model.predict([s]
input_string = input("Test iÃ§in bir string giriniz\n") 
print("Kategori: ",predict_category(input_string))

## BASÄ°T DOÄRUSAL REGRESYON
Veriler â€œxâ€ (baÄŸÄ±msÄ±z deÄŸiÅŸken) ve â€œyâ€ (baÄŸÄ±mlÄ± deÄŸiÅŸken) ikilileri ÅŸeklinde tanÄ±mlandÄ±.
data = [[2,8], [6,5], [7,7], [9,4], [8,6]]

â€œxyâ€ deÄŸiÅŸkenine â€œxâ€ ve â€œyâ€ deÄŸerlerinin Ã§arpÄ±mÄ± atandÄ±. â€œxortâ€ ve â€œyortâ€ deÄŸerlerine her bir x deÄŸerlerinin ortalamasÄ± ve y deÄŸerlernin ortalamasÄ± atandÄ±. 
xort = 0
yort =0
xy = 0
xsqr = 0
for i in range(len(data)):
    xy += (data[i][0] * data[i][1])
    xort += data[i][0]
    yort += data[i][1]
    xsqr += (data[i][0]**2)

xort /= len(data)
yort /= len(data)

â€œbâ€ (regresyon katsayÄ±sÄ±) daha Ã¶nce hesaplanan deÄŸerler kullanÄ±larak hesaplanmaktadÄ±r.

b = (xy - len(data) * xort * yort ) / (xsqr - len(data)*(xort**2))

â€œaâ€ (sabit) deÄŸeri de hesaplanan â€œbâ€ katsayÄ±sÄ± sayesinde hesaplanmaktadÄ±r.
a = yort - b*xort

KullanÄ±cÄ±dan hedef tahmini yapÄ±labilmesi iÃ§in bir deÄŸer alÄ±nmaktadÄ±r. 
input_string = input("Y tahmini yapabilmek iÃ§in x deÄŸerini giriniz \n")

Girilen deÄŸer, oluÅŸturulan hesaplama denklemi kullanÄ±larak bulunuyor.
y = a + b * int(input_string)
print("Y deÄŸeri: ",y)

Son olarak da hatalar bulunarak gerÃ§ek deÄŸer denkleminin hesaplanmasÄ± yapÄ±ldÄ± ve â€œyâ€ gerÃ§ek deÄŸeri yazdÄ±rÄ±ldÄ±.
y_head = []
for i in range(len(data)):
    appending = a + b * data[i][0]
    y_head.append(appending) 
top = 0
for i in range(len(data)):
    if len(data) < 30:
        top += ((data[i][1] - y_head[i]) **2)        
        s = (top/(len(data) -2)) ** (1/2)
print("GerÃ§ek deÄŸer denklemi = ",a,"+",b,"*","(x)","+",s)
gercek_deger = a+b*int(input_string)+s
print("\nGerÃ§ek deÄŸer: ",gercek_deger)


